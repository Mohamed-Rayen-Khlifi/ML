{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Feature Scaling\n#### Helps the model converge faster especially if your input features have widely different ranges of values especially if there are degree polynomials","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler, scale\nfrom sklearn.linear_model import SGDRegressor\n\n# Make sure to scale any data set you pass to the model, because it was trained with normalized values\nscaler = StandardScaler()\n\n### Z Scale the training data (X-mean)/standard_derivation\nX_norm = scaler.fit_transform(X_train) \n\n# Feed the scaled training set and get the predictions\nyhat = linear_model.predict(X_train_scaled)\n\n\n### Another way to scale generally with options\nscale(X_orig, axis=0, with_mean=True, with_std=True, copy=True)\n\n### Scikit-learn has a gradient descent regression model that performs best with normalized input\nsgdr = SGDRegressor(max_iter=1000)\nsgdr.fit(X_norm, y_train)\n\n# Make predictions with normalized data87775am\ny_pred_sgd = sgdr.predict(X_norm)","metadata":{},"execution_count":null,"outputs":[]}]}